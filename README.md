# An√°lise de V√≠deos do YouTube com PySpark

Projeto desenvolvido para aplicar leitura, escrita e manipula√ß√£o de dados em ambiente de Big Data utilizando **Apache Spark no Google Colab**. A an√°lise envolve arquivos p√∫blicos de estat√≠sticas de v√≠deos e coment√°rios da plataforma YouTube.

## Tecnologias Utilizadas

- Python 3
- Google Colab
- Apache Spark 3.3.1 (via PySpark)
- Parquet
- Spark SQL

## Arquivos Utilizados

- `videos-stats.csv`: informa√ß√µes sobre v√≠deos (visualiza√ß√µes, likes, etc.)
- `comments.csv`: base de coment√°rios feitos em v√≠deos

## Etapas Realizadas

- ‚úÖ Leitura dos arquivos `.csv` com e sem infer√™ncia de schema
- ‚úÖ Visualiza√ß√£o dos dados (`show`) e estrutura (`printSchema`)
- ‚úÖ Convers√£o e salvamento no formato `.parquet`
- ‚úÖ Cria√ß√£o de tabela `tb_videos` no cat√°logo do Spark
- ‚úÖ Consulta da tabela usando SQL no Spark
- ‚úÖ Upload e manipula√ß√£o de m√∫ltiplos arquivos em ambiente distribu√≠do

## üìä Objetivo

O objetivo √© simular tarefas comuns de um analista de dados em ambiente de Big Data, combinando dados de diferentes fontes e formatos. O projeto tamb√©m serve como base para etapas futuras de tratamento e an√°lise avan√ßada.

## Como Executar

1. Fa√ßa upload dos arquivos `videos-stats.csv` e `comments.csv` no Colab
2. Abra o notebook `leitura-escrita.ipynb`
3. Execute as c√©lulas passo a passo

> **Obs:** O ambiente Spark √© instalado diretamente no Colab nas primeiras c√©lulas.

## Autora

Projeto desenvolvido por [Lu Carvalho](https://github.com/Lucarvalho123) como parte do estudo pr√°tico sobre ferramentas de Big Data e an√°lise de dados com Spark.

---

